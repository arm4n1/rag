{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0390718-6aa9-44e1-8cc8-7774b56c59e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\capstone\\test4.0\\venv\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: faiss-cpu in d:\\capstone\\test4.0\\venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: sentence-transformers in d:\\capstone\\test4.0\\venv\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: langchain in d:\\capstone\\test4.0\\venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: PyPDF2 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in d:\\capstone\\test4.0\\venv\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: packaging in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langchain) (0.3.79)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langchain) (0.4.37)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langchain) (2.12.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langchain) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\capstone\\test4.0\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests faiss-cpu sentence-transformers langchain PyPDF2 numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e720708d-92c0-4268-a444-8c70ecc23838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00259b8f-e5cb-4dbe-94c6-caa1a0d0a722",
   "metadata": {},
   "source": [
    "### KONFIGURASI DASAR OPENROUTER + GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a0ad88-33b9-4c46-b2ad-2a78f8ab5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_KEY = \"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\"\n",
    "OPENROUTER_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "MODEL = \"z-ai/glm-4.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92374c-f9e5-4915-8ed2-61d52fa58ecc",
   "metadata": {},
   "source": [
    "### PEMANGGIL MODEL GLM VIA OPENROUTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dedeecc-4b69-4d4a-a477-8716c8bd854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_glm(prompt: str, temperature: float = 0.0) -> str:\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Kamu adalah sistem penilai otomatis. Jawab hanya dalam format JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(OPENROUTER_URL, headers=headers, json=payload, timeout=120)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Gagal memanggil GLM: {e}\")\n",
    "        print(\"Respons mentah:\", r.text if 'r' in locals() else \"tidak ada respons\")\n",
    "        return \"{}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cb044-e1c9-4d9c-a39c-dfb21192cfca",
   "metadata": {},
   "source": [
    "### LOAD RUBRIK PENILAIAN (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2527795-1c87-4bde-b5ff-301f9a62c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rubric_json(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        rubric_data = json.load(f)\n",
    "    return json.dumps(rubric_data, indent=2, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe78df-2f74-4430-bb7a-2211c0167be9",
   "metadata": {},
   "source": [
    "### EKSTRAK TEKS DARI PDF MAHASISWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "665c8d82-f703-48ef-8057-0af1940547fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    pages = []\n",
    "    for page in reader.pages:\n",
    "        p = page.extract_text() or \"\"\n",
    "        if p.strip():\n",
    "            pages.append(p)\n",
    "    return \"\\n\".join(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24688f4-18ba-49fe-a4c0-b1b34172c032",
   "metadata": {},
   "source": [
    "### chunk text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f5642ab-3b77-4732-a5ea-766f55c9548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    if not text or not text.strip():\n",
    "        return []\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = splitter.split_text(text)\n",
    "    return [c.strip() for c in chunks if c and c.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f6a741-d91c-4505-a214-e9bb117cdd2a",
   "metadata": {},
   "source": [
    "### encoding ke Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42a0ba23-a8c7-49a5-a1a0-6ec7cf33a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorDB:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.embedder = SentenceTransformer(model_name)\n",
    "        self.index = None\n",
    "        self.texts = []\n",
    "\n",
    "    def build(self, texts):\n",
    "        self.texts = texts\n",
    "        embeddings = self.embedder.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "        embeddings = np.asarray(embeddings, dtype=np.float32)\n",
    "        dim = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dim)\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "    def search(self, query, k=3):\n",
    "        q_emb = self.embedder.encode([query], convert_to_numpy=True)\n",
    "        q_emb = np.asarray(q_emb, dtype=np.float32)\n",
    "        D, I = self.index.search(q_emb, k)\n",
    "        return [self.texts[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5086c3f9-c529-42b5-a16f-bd7003b8fc13",
   "metadata": {},
   "source": [
    "### Build Promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a615c923-2a73-4426-ad43-4fd978876723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_with_rag(rubric_json: str, evidence: str) -> str:\n",
    "    return f\"\"\"\n",
    "Anda adalah sistem auto-grading untuk Learning Management System (LMS).\n",
    "Tugas Anda adalah menilai laporan mahasiswa berdasarkan **rubrik penilaian (JSON)** dan **evidence dari hasil pencarian dokumen (RAG)**.\n",
    "\n",
    "Gunakan *hanya informasi dari evidence di bawah ini* sebagai dasar penilaian.\n",
    "JANGAN mengarang isi di luar evidence.\n",
    "\n",
    "---\n",
    "\n",
    "### 📘 RUBRIK PENILAIAN (JSON)\n",
    "{rubric_json}\n",
    "\n",
    "---\n",
    "\n",
    "### 📄 EVIDENCE DARI LAPORAN (hasil pencarian RAG)\n",
    "Gunakan bagian-bagian teks berikut untuk mendukung setiap penilaian:\n",
    "{evidence}\n",
    "\n",
    "---\n",
    "\n",
    "### 📋 INSTRUKSI PENILAIAN\n",
    "1. Evaluasi **SEMUA sub-rubrik** yang ada pada rubrik JSON, jangan ada yang dilewatkan.\n",
    "2. Setiap level memiliki rentang nilai (`score_range`). Pilih **nilai numerik** dalam rentang itu, bukan hanya ujungnya.\n",
    "   - Contoh: jika sesuai level B (61–80), boleh kasih 70 atau 75 tergantung kualitas.\n",
    "   - Jika isi tidak mencukupi, tetap tampilkan sub-rubrik tersebut dengan level terendah dan beri alasan.\n",
    "3. Gunakan bukti dari bagian *Evidence* di atas untuk setiap keputusan penilaian.\n",
    "   - Jika ada kalimat pendukung, sebutkan ringkas potongan teks evidence yang relevan.\n",
    "4. Sertakan alasan singkat (1–3 kalimat) yang berdasarkan evidence.\n",
    "5. Cantumkan bobot (`assignment_sub_rubrics.weight`).\n",
    "6. Hitung nilai total berdasarkan skor × bobot.\n",
    "7. Tambahkan confidence score untuk setiap sub-rubrik dan keseluruhan (`overall_confidence`).\n",
    "\n",
    "---\n",
    "\n",
    "### 📤 FORMAT OUTPUT WAJIB (JSON)\n",
    "Jawaban akhir **HARUS** mengikuti struktur JSON berikut:\n",
    "\n",
    "{{\n",
    "  \"grading_result\": [\n",
    "    {{\n",
    "      \"sub_rubric\": \"Nama Sub Rubrik\",\n",
    "      \"selected_level\": \"A/B/C/...\",\n",
    "      \"score_awarded\": 0-100,\n",
    "      \"weight\": 0-100,\n",
    "      \"reason\": \"alasan singkat berdasarkan evidence\",\n",
    "      \"evidence_quote\": \"potongan teks relevan dari evidence\",\n",
    "      \"confidence\": 0.0-1.0\n",
    "    }}\n",
    "  ],\n",
    "  \"final_score\": 0-100,\n",
    "  \"overall_confidence\": 0.0-1.0\n",
    "}}\n",
    "\n",
    "Output tidak boleh berisi penjelasan tambahan di luar struktur JSON.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c70777a-a10f-405b-8052-fd4a453bdfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat rubrik penilaian...\n",
      "Mengekstrak teks dari PDF...\n",
      "Memecah teks menjadi potongan kecil...\n",
      "Membangun database vektor (FAISS)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3803f150bd7c43379b9c3eb6e6631813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari evidence relevan...\n",
      "Menyusun prompt untuk GLM...\n",
      "Mengirim prompt ke GLM melalui OpenRouter...\n",
      "\n",
      ">>> HASIL PENILAIAN (JSON):\n",
      "```json\n",
      "{\n",
      "  \"grading_result\": [\n",
      "    {\n",
      "      \"sub_rubric\": \"Dasar Teori\",\n",
      "      \"selected_level\": \"A\",\n",
      "      \"score_awarded\": 90,\n",
      "      \"weight\": 10,\n",
      "      \"reason\": \"Dasar teori dikemukakan dengan jelas dan informatif, mencakup penjelasan tentang variabel, operator aritmatika, dan konversi tipe data dengan definisi yang tepat.\",\n",
      "      \"evidence_quote\": \"Variabel merupakan suatu tempat yang tersedia di memori komputer yang berguna untuk menyimpan data baik itu huruf, rangkaian huruf (ekuivalen dengan kata atau kalimat), angka (bilangan bulat/desimal), atau karakter khusus.\",\n",
      "      \"confidence\": 0.9\n",
      "    },\n",
      "    {\n",
      "      \"sub_rubric\": \"Kode Program\",\n",
      "      \"selected_level\": \"B\",\n",
      "      \"score_awarded\": 70,\n",
      "      \"weight\": 50,\n",
      "      \"reason\": \"Evidence hanya menunjukkan potongan kode terbatas tanpa menampilkan keseluruhan program atau informasi jelas tentang efisiensi program dan penamaan variabel.\",\n",
      "      \"evidence_quote\": \"Fungsi input() digunakan untuk mengambil input dari si pengguna, pengguna diminta untuk memasukkan pilihan mereka (1, 2, atau 3) dan Fungsi int() digunakan untuk mengonversi nilai input yang diterima sebagai string menjadi tipe data integer.\",\n",
      "      \"confidence\": 0.7\n",
      "    },\n",
      "    {\n",
      "      \"sub_rubric\": \"Keterangan Baris Program\",\n",
      "      \"selected_level\": \"B\",\n",
      "      \"score_awarded\": 75,\n",
      "      \"weight\": 20,\n",
      "      \"reason\": \"Terdapat penjelasan untuk beberapa bagian kode, namun tidak semua baris code diberikan penjelasan secara lengkap.\",\n",
      "      \"evidence_quote\": \"Kode ini juga sama seperti nomor 3, tetapi kode ini untuk memilih pilihan jempol (Gajah) untuk menjadi pilihan di permain suit\",\n",
      "      \"confidence\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"sub_rubric\": \"Kesimpulan\",\n",
      "      \"selected_level\": \"B\",\n",
      "      \"score_awarded\": 75,\n",
      "      \"weight\": 20,\n",
      "      \"reason\": \"Kesimpulan dapat dipahami namun kurang detail dalam menjelaskan pembelajaran yang diperoleh dari program yang dibuat.\",\n",
      "      \"evidence_quote\": \"Secara keseluruhan, praktikum ini memberikan dasar yang kuat dalam pemrograman Python dan mempersiapkan kami untuk mempelajari konsep yang lebih kompleks dan penerapannya dalam proyek yang lebih besar.\",\n",
      "      \"confidence\": 0.85\n",
      "    }\n",
      "  ],\n",
      "  \"final_score\": 74,\n",
      "  \"overall_confidence\": 0.81\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    rubric_file = \"rubrik.JSON\"\n",
    "    pdf_file = \"Laprak _Minggu 2 dan 3_Kelompok 6.pdf\"\n",
    "\n",
    "    print(\"Memuat rubrik penilaian...\")\n",
    "    rubric_json = load_rubric_json(rubric_file)\n",
    "\n",
    "    print(\"Mengekstrak teks dari PDF...\")\n",
    "    pdf_text = extract_text_from_pdf(pdf_file)\n",
    "    if not pdf_text:\n",
    "        raise SystemExit(\"PDF kosong (kemungkinan hasil scan)\")\n",
    "\n",
    "    print(\"Memecah teks menjadi potongan kecil...\")\n",
    "    chunks = chunk_text(pdf_text)\n",
    "    if not chunks:\n",
    "        chunks = [pdf_text[:20000]]\n",
    "\n",
    "    print(\"Membangun database vektor (FAISS)...\")\n",
    "    vectordb = SimpleVectorDB()\n",
    "    vectordb.build(chunks)\n",
    "\n",
    "    print(\"Mencari evidence relevan...\")\n",
    "    query = \"Evaluasi laporan sesuai rubrik penilaian. Cari bukti tujuan penelitian, metode, dan hasil.\"\n",
    "    evidence_chunks = vectordb.search(query, k=5)\n",
    "    evidence = \"\\n\\n---\\n\\n\".join(evidence_chunks)\n",
    "\n",
    "    print(\"Menyusun prompt untuk GLM...\")\n",
    "    prompt = build_prompt_with_rag(rubric_json, evidence)\n",
    "\n",
    "    print(\"Mengirim prompt ke GLM melalui OpenRouter...\")\n",
    "    response = call_glm(prompt)\n",
    "\n",
    "    print(\"\\n>>> HASIL PENILAIAN (JSON):\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd249802-7e2d-43c6-b751-7b7296dc7ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
