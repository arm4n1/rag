2025-10-29 14:38:37 - root - INFO - ============================================================
2025-10-29 14:38:37 - root - INFO - RAG AUTO-GRADING SYSTEM v2.0 - Session Started
2025-10-29 14:38:37 - root - INFO - ============================================================
2025-10-29 14:38:37 - root - INFO - Validating configuration from .env file...
2025-10-29 14:38:37 - root - INFO - Configuration validation passed
2025-10-29 14:38:37 - root - INFO - Output folder created/verified: D:\RAG\output
2025-10-29 14:38:37 - root - INFO - Starting batch processing...
2025-10-29 14:38:37 - root - INFO - Extracting PDF: data\LP 2 & 3_Kelompok 8.pdf
2025-10-29 14:38:38 - root - INFO - Successfully extracted 15 pages from LP 2 & 3_Kelompok 8
2025-10-29 14:38:38 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-10-29 14:38:38 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-10-29 14:38:41 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-10-29 14:45:03 - root - INFO - Building FAISS index with chunk_size=1000, overlap=200
2025-10-29 14:45:03 - root - INFO - Created 16 chunks from text
2025-10-29 14:45:03 - root - INFO - Generating embeddings using model: SentenceTransformer(
  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
  (2): Normalize()
)
2025-10-29 14:45:04 - root - INFO - FAISS index built successfully with 16 vectors, dimension=384
2025-10-29 14:45:04 - root - INFO - Starting grading process
2025-10-29 14:45:04 - root - INFO - Processing 4 sub-rubrics
2025-10-29 14:45:04 - root - INFO - Collected 10 unique evidence chunks
2025-10-29 14:45:04 - root - INFO - Calling LLM API: z-ai/glm-4.5
2025-10-29 14:45:59 - root - INFO - Received LLM response, length: 2283 characters
2025-10-29 14:45:59 - root - INFO - Grading completed. Final score: 80
2025-10-29 14:45:59 - root - INFO - Generating Excel report to: output\grading_results_20251029_144559.xlsx
2025-10-29 14:55:17 - root - INFO - ============================================================
2025-10-29 14:55:17 - root - INFO - RAG AUTO-GRADING SYSTEM v2.0 - Session Started
2025-10-29 14:55:17 - root - INFO - ============================================================
2025-10-29 14:55:17 - root - INFO - Validating configuration from .env file...
2025-10-29 14:55:17 - root - INFO - Configuration validation passed
2025-10-29 14:55:17 - root - INFO - Output folder created/verified: D:\RAG\output
2025-10-29 14:55:17 - root - INFO - Starting batch processing...
2025-10-29 14:55:17 - root - INFO - Extracting PDF: data\LP 2 & 3_Kelompok 4.pdf
2025-10-29 14:55:17 - root - INFO - Successfully extracted 16 pages from LP 2 & 3_Kelompok 4
2025-10-29 14:55:17 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-10-29 14:55:17 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-10-29 14:55:22 - root - INFO - Building FAISS index with chunk_size=1000, overlap=200
2025-10-29 14:55:22 - root - INFO - Created 22 chunks from text
2025-10-29 14:55:22 - root - INFO - Generating embeddings using model: SentenceTransformer(
  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
  (2): Normalize()
)
2025-10-29 14:55:23 - root - INFO - FAISS index built successfully with 22 vectors, dimension=384
2025-10-29 14:55:23 - root - INFO - Starting grading process
2025-10-29 14:55:23 - root - INFO - Processing 4 sub-rubrics
2025-10-29 14:55:23 - root - INFO - Collected 10 unique evidence chunks
2025-10-29 14:55:23 - root - INFO - Calling LLM API: z-ai/glm-4.5
2025-10-29 14:55:34 - root - INFO - Received LLM response, length: 2507 characters
2025-10-29 14:55:34 - root - INFO - Grading completed. Final score: 71.5
2025-10-29 14:55:34 - root - INFO - Extracting PDF: data\LP 2 & 3_Kelompok 8.pdf
2025-10-29 14:55:34 - root - INFO - Successfully extracted 15 pages from LP 2 & 3_Kelompok 8
2025-10-29 14:55:34 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-10-29 14:55:34 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-10-29 14:55:38 - root - INFO - Building FAISS index with chunk_size=1000, overlap=200
2025-10-29 14:55:38 - root - INFO - Created 16 chunks from text
2025-10-29 14:55:38 - root - INFO - Generating embeddings using model: SentenceTransformer(
  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
  (2): Normalize()
)
2025-10-29 14:55:39 - root - INFO - FAISS index built successfully with 16 vectors, dimension=384
2025-10-29 14:55:39 - root - INFO - Starting grading process
2025-10-29 14:55:39 - root - INFO - Processing 4 sub-rubrics
2025-10-29 14:55:39 - root - INFO - Collected 10 unique evidence chunks
2025-10-29 14:55:39 - root - INFO - Calling LLM API: z-ai/glm-4.5
2025-10-29 14:55:48 - root - INFO - Received LLM response, length: 2123 characters
2025-10-29 14:55:48 - root - INFO - Grading completed. Final score: 78.5
2025-10-29 14:55:48 - root - INFO - Generating Excel report to: output\grading_results_20251029_145548.xlsx
